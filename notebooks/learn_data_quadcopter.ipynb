{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc3bcf7d-2b70-4f75-9063-67161e33b639",
   "metadata": {},
   "source": [
    "# Training the function approximators (for Quadcopter)\n",
    "\n",
    "Given the dataset, we train $k$-NN, NN, and MDN to perform the trajectory prediction. They are evaluated based on the MSE and the % of collision free of the predicted trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "linear-stretch",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import random\n",
    "import logging\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "sys.path.append('../lib')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "from ocp import *\n",
    "from costs import *\n",
    "from ocp_utils import *\n",
    "from env_creator import EnvCreator, generate_sdf_rep\n",
    "from tensor_decomp import apply_tt\n",
    "from visualization_utils import plot_traj_projections, plot_traj_and_obs_3d\n",
    "\n",
    "import pybullet as p\n",
    "import pybullet_data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from regression import rbf\n",
    "import numpy.matlib\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "np.set_printoptions(precision=4, suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "freelance-chemical",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "082c36cb-3f5b-479c-a639-cd5052f320c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp_name = 'start_goal_fixed_100samples_5'\n",
    "# exp_name = 'var_start_goal_1000samples_no_waypoint'\n",
    "exp_name = 'var_start_goal_3000samples'\n",
    "exp_name = 'var_start_goal_1000samples_no_waypoint'\n",
    "exp_name = 'quad_mult_obs_var_start_goal_1000samples_2'\n",
    "exp_name = 'quad_mult_obs_var_start_goal_1000samples_two_obstacles'\n",
    "exp_name = 'quad_mult_obs_var_start_goal_1000samples_five_obstacles'\n",
    "exp_name = 'quad_mult_obs_var_start_goal_1000samples_three_obstacles'\n",
    "\n",
    "# exp_name = 'start_goal_fixed_300samples_1'\n",
    "# exp_name = 'mult_obs_var_start_goal_1000samples_1'\n",
    "# exp_name = 'mult_obs_var_start_goal_1000samples_teguh'\n",
    "# exp_name = 'start_goal_fixed_300samples_quadcopter'\n",
    "# exp_name = 'start_goal_fixed_300samples_1'\n",
    "# exp_name = 'mult_obs_fixed_start_goal_1000samples'\n",
    "# exp_name = 'mult_obs_100samples'\n",
    "# exp_name = '2_obs_var_start_goal_1000samples'\n",
    "# exp_name = '2_obs_100samples'\n",
    "# exp_name = 'start_goal_fixed_300samples_1'\n",
    "# exp_name = 'mult_obs_var_start_goal_500samples_1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ca25ca0-eb22-4df7-9545-02094e3a792f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of data points: 1660\n"
     ]
    }
   ],
   "source": [
    "raw_data = load_data(exp_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf3850d-f1a9-4e42-97c1-bde3f66d060f",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "#### Visualize data in pybullet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5de3f431-089f-4115-9f74-b9b822365da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "p.connect(p.DIRECT)\n",
    "p.setAdditionalSearchPath(pybullet_data.getDataPath())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b08c29-4c45-4c63-bb9e-4ef6f71432ea",
   "metadata": {},
   "source": [
    "#### Check true data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0a9d886-8152-46d7-b9fe-adf6dc40f58a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(False, False, True)\n",
      "According to data False\n"
     ]
    }
   ],
   "source": [
    "i = np.random.randint(len(raw_data))\n",
    "\n",
    "data = raw_data[i]\n",
    "x0, x_target = data['x0'][:3], data['xT'][:3]\n",
    "y_true =data['xs'][:,:3]\n",
    "obstacles = data['obstacles']\n",
    "quad_id, obj_id, init_id, target_id, border_id, obstacle_ids = init_pybullet_quadcopter(x0, x_target, obstacles)\n",
    "col_status= eval_collision_geometric_general(obstacles, obj_id, y_true, margin=-0.01)\n",
    "# print('According to current computation', np.max(col_status))\n",
    "\n",
    "print(check_cost_general(data['xs'], x_target, obstacles, obj_id))\n",
    "\n",
    "print('According to data',data['status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74ef2374-668d-4405-82cc-c007b4e9214d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_traj(y_true, obj_id, dt=0.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6685061a-485f-4e4f-8b8a-dfb5bfbb4234",
   "metadata": {},
   "source": [
    "## Learn from the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adecac97-fcf3-4933-bdb1-b627f23d5173",
   "metadata": {},
   "source": [
    "#### Filter the data\n",
    "\n",
    "Only use the data when the trajectory:\n",
    "- Has no collision\n",
    "- Has 'True' as ddp status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c29d692-2d6d-449d-855d-83b357b50e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "status_ddp  = np.array([data['status'] for data in raw_data]) # Trajectories that have 'True' status from ddp\n",
    "status_col  = np.array([data['collision_status'] for data in raw_data]) # Trajectories that have 'True' status based on collisionfinal_status = status_ddp\n",
    "final_status = np.logical_and(status_ddp, np.logical_not(status_col))\n",
    "status_ddp, status_col = status_ddp[final_status], status_col[final_status]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1c9b78-840f-4f9c-aa4e-b8527950a0df",
   "metadata": {},
   "source": [
    "#### Extract the useful data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28751fbc-0bda-44a4-9343-b1dd4fa37a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_max = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "786cd6c8-2fe9-44d4-a091-0883eefb55b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs_set = np.array([data['xs'][:,:12] for data in raw_data])[final_status][:N_max]\n",
    "init_positions = np.array([data['x0'][:12] for data in raw_data])[final_status][:N_max]\n",
    "goal_positions = np.array([data['xT'][:12] for data in raw_data])[final_status][:N_max]\n",
    "obs_set = np.array([data['obstacles'] for data in raw_data])[final_status][:N_max]\n",
    "cost_set = np.array([data['cost'] for data in raw_data])[final_status][:N_max]\n",
    "collision_set = np.array([data['collision_status'] for data in raw_data])[final_status][:N_max]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "43bd460c-ddbc-4979-861f-be6388436ef3",
   "metadata": {},
   "source": [
    "bounds = np.ones((3,2))\n",
    "bounds[:,0] *= -1\n",
    "voxel_size = 0.05\n",
    "env_builder = EnvCreator(bounds, voxel_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743c342a-8310-4329-8bf3-3800b8e6207e",
   "metadata": {},
   "source": [
    "#### Generate sdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "301c5e96-56a5-4d71-930d-efd14b01fa0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdf import *\n",
    "\n",
    "from tensor_decomp import apply_tt, orthogonalize, apply_parafac\n",
    "def generate_tt_sdf(obstacles, tt_rank = 3):\n",
    "    fs = []\n",
    "    for obstacle in obstacles:\n",
    "        pos = obstacle['pos']\n",
    "        if obstacle['obs_type'] == p.GEOM_SPHERE:\n",
    "            rad = obstacle['rad']\n",
    "            f = sphere(rad).translate(pos)\n",
    "        elif obstacle['obs_type'] == p.GEOM_CAPSULE:\n",
    "            rad = obstacle['rad']\n",
    "            length = obstacle['length']\n",
    "            f = capsule([0,0,-length/2], [0,0,length/2], rad).translate(pos)\n",
    "        elif obstacle['obs_type'] == p.GEOM_BOX:\n",
    "            box_size = obstacle['halfExtents']\n",
    "            f = box([box_size[0]*2,box_size[1]*2,box_size[2]*2] ).translate(pos)\n",
    "        fs.append(f)\n",
    "    f_t = fs[0]\n",
    "    for f in fs[1:]:\n",
    "        f_t = f_t | f\n",
    "    points = f_t(env_builder.voxel_grid).reshape(40,40,40)\n",
    "    tt_sdf_vol = apply_tt(points, rank=tt_rank) #.copy(order='C').astype(np.float32)\n",
    "    tt_sdf_orth = orthogonalize(tt_sdf_vol)\n",
    "    return points, tt_sdf_vol, tt_sdf_orth"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b86d429f-1d4e-4764-bc60-56bd364a2911",
   "metadata": {},
   "source": [
    "points, tt_sdf_vol, tt_sdf_orth = generate_tt_sdf(obstacles, 3)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5535315b-cd63-44c3-8740-7e17421217bd",
   "metadata": {},
   "source": [
    "import trimesh\n",
    "\n",
    "mesh = env_builder.render_voxel_view(points, return_mesh=True)\n",
    "\n",
    "scene = trimesh.Scene()\n",
    "scene.add_geometry(mesh)\n",
    "scene.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4da8d8b",
   "metadata": {},
   "source": [
    "#### Convert environment in SDF representation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e801004-622f-47a0-8b0f-dd5d76ed3ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdf import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ac939ff-777e-44fb-8549-d7c0a640333f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "582\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "589\n",
      "590\n",
      "591\n",
      "592\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n",
      "597\n",
      "598\n",
      "599\n",
      "600\n",
      "601\n",
      "602\n",
      "603\n",
      "604\n",
      "605\n",
      "606\n",
      "607\n",
      "608\n",
      "609\n",
      "610\n",
      "611\n",
      "612\n",
      "613\n",
      "614\n",
      "615\n",
      "616\n",
      "617\n",
      "618\n",
      "619\n",
      "620\n",
      "621\n",
      "622\n",
      "623\n",
      "624\n",
      "625\n",
      "626\n",
      "627\n",
      "628\n",
      "629\n",
      "630\n",
      "631\n",
      "632\n",
      "633\n",
      "634\n",
      "635\n",
      "636\n",
      "637\n",
      "638\n",
      "639\n",
      "640\n",
      "641\n",
      "642\n",
      "643\n",
      "644\n",
      "645\n",
      "646\n",
      "647\n",
      "648\n",
      "649\n",
      "650\n",
      "651\n",
      "652\n",
      "653\n",
      "654\n",
      "655\n",
      "656\n",
      "657\n",
      "658\n",
      "659\n",
      "660\n",
      "661\n",
      "662\n",
      "663\n",
      "664\n",
      "665\n",
      "666\n",
      "667\n",
      "668\n",
      "669\n",
      "670\n",
      "671\n",
      "672\n",
      "673\n",
      "674\n",
      "675\n",
      "676\n",
      "677\n",
      "678\n",
      "679\n",
      "680\n",
      "681\n",
      "682\n",
      "683\n",
      "684\n",
      "685\n",
      "686\n",
      "687\n",
      "688\n",
      "689\n",
      "690\n",
      "691\n",
      "692\n",
      "693\n",
      "694\n",
      "695\n",
      "696\n",
      "697\n",
      "698\n",
      "699\n",
      "700\n",
      "701\n",
      "702\n",
      "703\n",
      "704\n",
      "705\n",
      "706\n",
      "707\n",
      "708\n",
      "709\n",
      "710\n",
      "711\n",
      "712\n",
      "713\n",
      "714\n",
      "715\n",
      "716\n",
      "717\n",
      "718\n",
      "719\n",
      "720\n",
      "721\n",
      "722\n",
      "723\n",
      "724\n",
      "725\n",
      "726\n",
      "727\n",
      "728\n",
      "729\n",
      "730\n",
      "731\n",
      "732\n",
      "733\n",
      "734\n",
      "735\n",
      "736\n",
      "737\n",
      "738\n",
      "739\n",
      "740\n",
      "741\n",
      "742\n",
      "743\n",
      "744\n",
      "745\n",
      "746\n",
      "747\n",
      "748\n",
      "749\n",
      "750\n",
      "751\n",
      "752\n",
      "753\n",
      "754\n",
      "755\n",
      "756\n",
      "757\n",
      "758\n",
      "759\n",
      "760\n",
      "761\n",
      "762\n",
      "763\n",
      "764\n",
      "765\n",
      "766\n",
      "767\n",
      "768\n",
      "769\n",
      "770\n",
      "771\n",
      "772\n",
      "773\n",
      "774\n",
      "775\n",
      "776\n",
      "777\n",
      "778\n",
      "779\n",
      "780\n",
      "781\n",
      "782\n",
      "783\n",
      "784\n",
      "785\n",
      "786\n",
      "787\n",
      "788\n",
      "789\n",
      "790\n",
      "791\n",
      "792\n",
      "793\n",
      "794\n",
      "795\n",
      "796\n",
      "797\n",
      "798\n",
      "799\n",
      "800\n",
      "801\n",
      "802\n",
      "803\n",
      "804\n",
      "805\n",
      "806\n",
      "807\n",
      "808\n",
      "809\n",
      "810\n",
      "811\n",
      "812\n",
      "813\n",
      "814\n",
      "815\n",
      "816\n",
      "817\n",
      "818\n",
      "819\n",
      "820\n",
      "821\n",
      "822\n",
      "823\n",
      "824\n",
      "825\n",
      "826\n",
      "827\n",
      "828\n",
      "829\n",
      "830\n",
      "831\n",
      "832\n",
      "833\n",
      "834\n",
      "835\n",
      "836\n",
      "837\n",
      "838\n",
      "839\n",
      "840\n",
      "841\n",
      "842\n",
      "843\n",
      "844\n",
      "845\n",
      "846\n",
      "847\n",
      "848\n",
      "849\n",
      "850\n",
      "851\n",
      "852\n",
      "853\n",
      "854\n",
      "855\n",
      "856\n",
      "857\n",
      "858\n",
      "859\n",
      "860\n",
      "861\n",
      "862\n",
      "863\n",
      "864\n",
      "865\n",
      "866\n",
      "867\n",
      "868\n",
      "869\n",
      "870\n",
      "871\n",
      "872\n",
      "873\n",
      "874\n",
      "875\n",
      "876\n",
      "877\n",
      "878\n",
      "879\n",
      "880\n",
      "881\n",
      "882\n",
      "883\n",
      "884\n",
      "885\n",
      "886\n",
      "887\n",
      "888\n",
      "889\n",
      "890\n",
      "891\n",
      "892\n",
      "893\n",
      "894\n",
      "895\n",
      "896\n",
      "897\n",
      "898\n",
      "899\n",
      "900\n",
      "901\n",
      "902\n",
      "903\n",
      "904\n",
      "905\n",
      "906\n",
      "907\n",
      "908\n",
      "909\n",
      "910\n",
      "911\n",
      "912\n",
      "913\n",
      "914\n",
      "915\n",
      "916\n",
      "917\n",
      "918\n",
      "919\n",
      "920\n",
      "921\n",
      "922\n",
      "923\n",
      "924\n",
      "925\n",
      "926\n",
      "927\n",
      "928\n",
      "929\n",
      "930\n",
      "931\n",
      "932\n",
      "933\n",
      "934\n",
      "935\n",
      "936\n",
      "937\n",
      "938\n",
      "939\n",
      "940\n",
      "941\n",
      "942\n",
      "943\n",
      "944\n",
      "945\n",
      "946\n",
      "947\n",
      "948\n",
      "949\n",
      "950\n",
      "951\n",
      "952\n",
      "953\n",
      "954\n",
      "955\n",
      "956\n",
      "957\n",
      "958\n",
      "959\n",
      "960\n",
      "961\n",
      "962\n",
      "963\n",
      "964\n",
      "965\n",
      "966\n",
      "967\n",
      "968\n",
      "969\n",
      "970\n",
      "971\n",
      "972\n",
      "973\n",
      "974\n",
      "975\n",
      "976\n",
      "977\n",
      "978\n",
      "979\n",
      "980\n",
      "981\n",
      "982\n",
      "983\n",
      "984\n",
      "985\n",
      "986\n",
      "987\n",
      "988\n",
      "989\n",
      "990\n",
      "991\n",
      "992\n",
      "993\n",
      "994\n",
      "995\n",
      "996\n",
      "997\n",
      "998\n",
      "999\n",
      "1000\n",
      "1001\n",
      "1002\n",
      "1003\n",
      "1004\n",
      "1005\n",
      "1006\n",
      "1007\n",
      "1008\n",
      "1009\n",
      "1010\n",
      "1011\n",
      "1012\n",
      "1013\n",
      "1014\n",
      "1015\n",
      "1016\n",
      "1017\n",
      "1018\n",
      "1019\n",
      "1020\n",
      "1021\n",
      "1022\n",
      "1023\n",
      "1024\n",
      "1025\n",
      "1026\n",
      "1027\n",
      "1028\n",
      "1029\n",
      "1030\n",
      "1031\n",
      "1032\n",
      "1033\n",
      "1034\n",
      "1035\n",
      "1036\n",
      "1037\n",
      "1038\n",
      "1039\n",
      "1040\n",
      "1041\n",
      "1042\n",
      "1043\n",
      "1044\n",
      "1045\n",
      "1046\n",
      "1047\n",
      "1048\n",
      "1049\n",
      "1050\n",
      "1051\n",
      "1052\n",
      "1053\n",
      "1054\n",
      "1055\n",
      "1056\n",
      "1057\n",
      "1058\n",
      "1059\n",
      "1060\n",
      "1061\n",
      "1062\n",
      "1063\n",
      "1064\n",
      "1065\n",
      "1066\n",
      "1067\n",
      "1068\n",
      "1069\n",
      "1070\n",
      "1071\n",
      "1072\n",
      "1073\n",
      "1074\n",
      "1075\n",
      "1076\n",
      "1077\n",
      "1078\n",
      "1079\n",
      "1080\n",
      "1081\n",
      "1082\n",
      "1083\n",
      "1084\n",
      "1085\n",
      "1086\n",
      "1087\n",
      "1088\n",
      "1089\n",
      "1090\n",
      "1091\n",
      "1092\n",
      "1093\n",
      "1094\n",
      "1095\n",
      "1096\n",
      "1097\n",
      "1098\n",
      "1099\n",
      "1100\n",
      "1101\n"
     ]
    }
   ],
   "source": [
    "voxel_res = 0.05 # voxel resolution in grid \n",
    "tt_rank = 3 # rank for tensor train decomposition -> should be as small as possible\n",
    "grid_boundaries = \\\n",
    " np.asarray([(-1,1),   # x\n",
    "             (-1,1),   # y\n",
    "             (-1,1)]   # z\n",
    "            ) # 3x2, columns: (min, max) in world coordinates in meters\n",
    "\n",
    "env_set = []\n",
    "tt_env_set = []\n",
    "full_data = []\n",
    "env_builder = EnvCreator(grid_boundaries, voxel_res)\n",
    "for i,obstacles in enumerate(obs_set):\n",
    "    print(i)\n",
    "    sdf_vol, tt_sdf_vol, tt_sdf_orth = generate_tt_sdf(obstacles, tt_rank)\n",
    "    env_set.append(sdf_vol.flatten())\n",
    "    tt_sdf_vol_array = np.concatenate([f.flatten() for f in tt_sdf_orth])\n",
    "    tt_env_set.append(tt_sdf_vol_array.flatten()) # factors of the tensor train decomposition of the sdf tensor \n",
    "\n",
    "env_set = np.array(env_set)\n",
    "tt_env_set = np.array(tt_env_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89bd582d-c3fb-443c-88a9-48e70f48240b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of uncompressed environment data input: (1102, 64000)\n",
      "Shape of compressed environment data input: (1102, 600)\n"
     ]
    }
   ],
   "source": [
    "# print('Shape of voxel grid: {}'.format(full_data[0]['sdf'].shape))\n",
    "print('Shape of uncompressed environment data input: {}'.format(env_set.shape))\n",
    "print('Shape of compressed environment data input: {}'.format(tt_env_set.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7466455a-1af9-4ffc-a7e5-492362a997e6",
   "metadata": {},
   "source": [
    "#### Construct the input output\n",
    "\n",
    "Current system = point mass \n",
    "\n",
    "__input__:\n",
    "- environment (tt-sdf representation) _or_ obstacle parameters\n",
    "\n",
    "if dataset with varying start and goal positions additionally: \n",
    "- start_position of pointmass \n",
    "- target_position of pointmass\n",
    "\n",
    "__output__:\n",
    "- path trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e35229cc-353d-4b6e-b8ca-47e276df57d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_tt_rep = True # set this variable to use tt_representations as input variables \n",
    "start_goal_fixed = False # indicates whether to use start and goal position as additional input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "251a9336-306a-4ffa-bec5-b4b749127a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data instances: 1102\n",
      "(1102, 624)\n"
     ]
    }
   ],
   "source": [
    "if use_tt_rep and start_goal_fixed: \n",
    "    x_inputs = tt_env_set\n",
    "elif use_tt_rep and not start_goal_fixed: \n",
    "    x_inputs = np.concatenate([tt_env_set, init_positions, goal_positions], axis=1)\n",
    "else: \n",
    "    x_inputs = np.concatenate([r_set[:,None], p_set], axis=1) # use obstacle parametrization instead \n",
    "\n",
    "N = len(x_inputs)\n",
    "D_in = x_inputs.shape[1]\n",
    "Dx = 3 #dimensions of point mass system (xyz)\n",
    "T = 101 #number of time steps\n",
    "print('Number of data instances: {}'.format(N))\n",
    "print(x_inputs.shape)\n",
    "x_outputs = xs_set.reshape(N,-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7c15b5-a600-4546-8d0d-53ce18823b00",
   "metadata": {},
   "source": [
    "#### Separate into train and test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6aa22269-e406-4813-8f50-f4523b6abf96",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = len(x_inputs)\n",
    "indices = np.arange(n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "63a2a75a-3644-44c0-8f46-ace44c1d185a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test, train_idx, test_idx = train_test_split(x_inputs, x_outputs, indices, random_state=3, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "75562741-fd06-4608-a103-67b3ba16b8ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " (771, 624) \n",
      " (771, 1212) \n",
      " (331, 624) \n",
      " (331, 1212)\n"
     ]
    }
   ],
   "source": [
    "print('\\n',x_train.shape,'\\n', y_train.shape,'\\n', x_test.shape,'\\n', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8599788a-e583-400c-b658-5c80da0f6935",
   "metadata": {},
   "source": [
    "#### Use Dimensionality Reduction (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "028bfa6e-6271-401c-8592-26f5ae857d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_pca = True\n",
    "use_rbf = False\n",
    "\n",
    "if use_pca:\n",
    "    K = 25\n",
    "    pca = PCA(n_components=K)\n",
    "    y_train_pca = pca.fit_transform(y_train)\n",
    "    y_test_pca = pca.transform(y_test)\n",
    "    D_out = y_train_pca.shape[1]\n",
    "elif use_rbf:\n",
    "    rbf_transform = rbf(D=3, K = 8, offset = 20, width = 15, T = T)\n",
    "    Phi = rbf_transform.create_RBF()\n",
    "\n",
    "    plt.plot(Phi)\n",
    "    plt.show()\n",
    "    y_train_rbf = rbf_transform.transform(y_train.reshape(-1,T,Dx))\n",
    "    y_test_rbf = rbf_transform.transform(y_test.reshape(-1,T,Dx))\n",
    "    D_out = y_train_rbf.shape[1]\n",
    "else:\n",
    "    D_out = y_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1393d208-f0e6-46b7-a413-6e02b40d02fc",
   "metadata": {},
   "source": [
    "#### Save training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7beee90b-c450-44a7-a453-1500e9485a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dict()\n",
    "if use_pca:\n",
    "    data['pca'] = pca\n",
    "elif use_rbf:\n",
    "    data['rbf'] = rbf_transform\n",
    "    \n",
    "data['x_inputs'] = x_inputs\n",
    "data['x_outputs'] = x_outputs\n",
    "data['obstacles'] = obs_set\n",
    "data['tt_env_set'] = tt_env_set\n",
    "# data['env_set'] = env_set\n",
    "data['tt_rank'] = tt_rank\n",
    "data['voxel_res'] = voxel_res\n",
    "data['use_pca'] = use_pca\n",
    "data['use_rbf'] = use_rbf\n",
    "np.save('training_data/data_'+ exp_name, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41384a4d-4984-4f98-beca-f114a0eb2627",
   "metadata": {},
   "source": [
    "#### Load training data"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ded11256-f078-4914-9da3-e7f9360550b8",
   "metadata": {},
   "source": [
    "data = np.load('training_data/data_'+ exp_name)\n",
    "use_pca = data['use_pca']\n",
    "use_rbf = data['use_rbf']\n",
    "if use_pca:\n",
    "    pca = data['pca'] \n",
    "elif use_rbf:\n",
    "    rbf_transform = data['rbf']\n",
    "    \n",
    "x_inputs = data['x_inputs']\n",
    "x_outputs = data['x_outputs'] \n",
    "obs_set = data['obstacles']\n",
    "tt_env_set = data['tt_env_set']\n",
    "env_set = data['env_set']\n",
    "D_in = x_inputs.shape[1]\n",
    "D_out = x_outputs.shape[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74373c2f-f1b3-4a16-88f4-e0f0852e241c",
   "metadata": {},
   "source": [
    "## Create & Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7991502d-089d-4e31-9df7-7a876ed8d4d7",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 0. Set predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b0dc12d3-2625-45d1-b0ca-6a1aed8ac4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set choice of predictor here: \n",
    "predictor_dct = {0: 'k-nn', 1: 'gpr', 2:'nn', 3: 'mdn'}\n",
    "predictor = predictor_dct[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbec7d1-ab35-46c4-beaf-b62247dbf232",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "#### 1. Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "992f3085-3f8d-4258-a4b0-efbab9262e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = Sequential([\n",
    "    Dense(256, activation='relu', input_shape=(D_in,)),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(D_out)\n",
    "])\n",
    "\n",
    "#nn.summary()\n",
    "\n",
    "nn.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0002), loss='mse') # set loss and optimizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e0f09471-7962-4249-b274-527da0319855",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 2.5414 - val_loss: 1.2644\n",
      "Epoch 2/300\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 1.0878 - val_loss: 1.2081\n",
      "Epoch 3/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 1.0567 - val_loss: 1.1937\n",
      "Epoch 4/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 1.0475 - val_loss: 1.2089\n",
      "Epoch 5/300\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 1.0343 - val_loss: 1.2009\n",
      "Epoch 6/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 1.0350 - val_loss: 1.1988\n",
      "Epoch 7/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 1.0175 - val_loss: 1.1975\n",
      "Epoch 8/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 1.0101 - val_loss: 1.1908\n",
      "Epoch 9/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 1.0028 - val_loss: 1.1969\n",
      "Epoch 10/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 1.0088 - val_loss: 1.2000\n",
      "Epoch 11/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.9950 - val_loss: 1.1788\n",
      "Epoch 12/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.9899 - val_loss: 1.1735\n",
      "Epoch 13/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.9826 - val_loss: 1.1854\n",
      "Epoch 14/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.9751 - val_loss: 1.2001\n",
      "Epoch 15/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.9719 - val_loss: 1.1693\n",
      "Epoch 16/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.9685 - val_loss: 1.1653\n",
      "Epoch 17/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.9650 - val_loss: 1.1853\n",
      "Epoch 18/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.9619 - val_loss: 1.1874\n",
      "Epoch 19/300\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.9541 - val_loss: 1.1933\n",
      "Epoch 20/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.9467 - val_loss: 1.1815\n",
      "Epoch 21/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.9339 - val_loss: 1.1721\n",
      "Epoch 22/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.9418 - val_loss: 1.1938\n",
      "Epoch 23/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.9294 - val_loss: 1.1625\n",
      "Epoch 24/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.9201 - val_loss: 1.1810\n",
      "Epoch 25/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.9181 - val_loss: 1.1972\n",
      "Epoch 26/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.9150 - val_loss: 1.1941\n",
      "Epoch 27/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.9066 - val_loss: 1.1555\n",
      "Epoch 28/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.9022 - val_loss: 1.1621\n",
      "Epoch 29/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.8908 - val_loss: 1.1642\n",
      "Epoch 30/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.8931 - val_loss: 1.1754\n",
      "Epoch 31/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.8797 - val_loss: 1.1547\n",
      "Epoch 32/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.8742 - val_loss: 1.1401\n",
      "Epoch 33/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.8930 - val_loss: 1.1616\n",
      "Epoch 34/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.8625 - val_loss: 1.1531\n",
      "Epoch 35/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.8652 - val_loss: 1.1527\n",
      "Epoch 36/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.8530 - val_loss: 1.1830\n",
      "Epoch 37/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.8545 - val_loss: 1.1440\n",
      "Epoch 38/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.8324 - val_loss: 1.1407\n",
      "Epoch 39/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.8379 - val_loss: 1.1399\n",
      "Epoch 40/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.8176 - val_loss: 1.1436\n",
      "Epoch 41/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.8122 - val_loss: 1.1537\n",
      "Epoch 42/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.8123 - val_loss: 1.1624\n",
      "Epoch 43/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.7977 - val_loss: 1.1698\n",
      "Epoch 44/300\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.8044 - val_loss: 1.1210\n",
      "Epoch 45/300\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.7818 - val_loss: 1.1321\n",
      "Epoch 46/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.7760 - val_loss: 1.1209\n",
      "Epoch 47/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.7669 - val_loss: 1.1245\n",
      "Epoch 48/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.7694 - val_loss: 1.1154\n",
      "Epoch 49/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.7760 - val_loss: 1.1277\n",
      "Epoch 50/300\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.7635 - val_loss: 1.1446\n",
      "Epoch 51/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.7442 - val_loss: 1.1056\n",
      "Epoch 52/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.7416 - val_loss: 1.1181\n",
      "Epoch 53/300\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.7330 - val_loss: 1.1646\n",
      "Epoch 54/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.7227 - val_loss: 1.1175\n",
      "Epoch 55/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.7120 - val_loss: 1.1249\n",
      "Epoch 56/300\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.7050 - val_loss: 1.0955\n",
      "Epoch 57/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.7012 - val_loss: 1.0918\n",
      "Epoch 58/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.6860 - val_loss: 1.1370\n",
      "Epoch 59/300\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.6797 - val_loss: 1.1006\n",
      "Epoch 60/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.6709 - val_loss: 1.1043\n",
      "Epoch 61/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.6717 - val_loss: 1.1169\n",
      "Epoch 62/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.6724 - val_loss: 1.1155\n",
      "Epoch 63/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.6776 - val_loss: 1.0737\n",
      "Epoch 64/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.6580 - val_loss: 1.0763\n",
      "Epoch 65/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.6374 - val_loss: 1.0847\n",
      "Epoch 66/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.6349 - val_loss: 1.0900\n",
      "Epoch 67/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.6402 - val_loss: 1.1011\n",
      "Epoch 68/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.6222 - val_loss: 1.0706\n",
      "Epoch 69/300\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.6189 - val_loss: 1.0430\n",
      "Epoch 70/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.6200 - val_loss: 1.0385\n",
      "Epoch 71/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.5983 - val_loss: 1.0787\n",
      "Epoch 72/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.5871 - val_loss: 1.0640\n",
      "Epoch 73/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.5809 - val_loss: 1.1005\n",
      "Epoch 74/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.5791 - val_loss: 1.0653\n",
      "Epoch 75/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.5661 - val_loss: 1.0448\n",
      "Epoch 76/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.5601 - val_loss: 1.0378\n",
      "Epoch 77/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.5450 - val_loss: 1.0267\n",
      "Epoch 78/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.5400 - val_loss: 1.0257\n",
      "Epoch 79/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.5335 - val_loss: 1.0567\n",
      "Epoch 80/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.5445 - val_loss: 1.0288\n",
      "Epoch 81/300\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.5217 - val_loss: 0.9996\n",
      "Epoch 82/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.5239 - val_loss: 1.0229\n",
      "Epoch 83/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.5085 - val_loss: 1.0502\n",
      "Epoch 84/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.5224 - val_loss: 1.0871\n",
      "Epoch 85/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.5294 - val_loss: 1.0076\n",
      "Epoch 86/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.4997 - val_loss: 0.9977\n",
      "Epoch 87/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.4918 - val_loss: 0.9802\n",
      "Epoch 88/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.4883 - val_loss: 0.9894\n",
      "Epoch 89/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.4909 - val_loss: 0.9826\n",
      "Epoch 90/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.4863 - val_loss: 0.9880\n",
      "Epoch 91/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.4603 - val_loss: 0.9781\n",
      "Epoch 92/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.4539 - val_loss: 0.9813\n",
      "Epoch 93/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.4545 - val_loss: 1.0126\n",
      "Epoch 94/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.4524 - val_loss: 1.0117\n",
      "Epoch 95/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.4732 - val_loss: 1.0180\n",
      "Epoch 96/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.4527 - val_loss: 1.0002\n",
      "Epoch 97/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.4334 - val_loss: 1.0039\n",
      "Epoch 98/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.4356 - val_loss: 0.9963\n",
      "Epoch 99/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.4407 - val_loss: 0.9895\n",
      "Epoch 100/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.4519 - val_loss: 0.9646\n",
      "Epoch 101/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.4433 - val_loss: 1.0668\n",
      "Epoch 102/300\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.4277 - val_loss: 0.9743\n",
      "Epoch 103/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.4283 - val_loss: 0.9751\n",
      "Epoch 104/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.3972 - val_loss: 0.9556\n",
      "Epoch 105/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.4023 - val_loss: 0.9974\n",
      "Epoch 106/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.4052 - val_loss: 0.9864\n",
      "Epoch 107/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.3962 - val_loss: 0.9986\n",
      "Epoch 108/300\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.3907 - val_loss: 0.9721\n",
      "Epoch 109/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.3865 - val_loss: 1.0048\n",
      "Epoch 110/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.3819 - val_loss: 0.9503\n",
      "Epoch 111/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.3735 - val_loss: 0.9429\n",
      "Epoch 112/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.3764 - val_loss: 0.9638\n",
      "Epoch 113/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.3810 - val_loss: 0.9407\n",
      "Epoch 114/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.3631 - val_loss: 0.9260\n",
      "Epoch 115/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.3593 - val_loss: 0.9280\n",
      "Epoch 116/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.3492 - val_loss: 0.9653\n",
      "Epoch 117/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.3674 - val_loss: 0.9528\n",
      "Epoch 118/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.3500 - val_loss: 0.9277\n",
      "Epoch 119/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.3418 - val_loss: 0.9574\n",
      "Epoch 120/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.3469 - val_loss: 0.9347\n",
      "Epoch 121/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.3299 - val_loss: 0.9372\n",
      "Epoch 122/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.3350 - val_loss: 0.9593\n",
      "Epoch 123/300\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.3319 - val_loss: 0.9441\n",
      "Epoch 124/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.3296 - val_loss: 0.9603\n",
      "Epoch 125/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.3417 - val_loss: 0.9388\n",
      "Epoch 126/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.3448 - val_loss: 0.9229\n",
      "Epoch 127/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.3217 - val_loss: 0.9194\n",
      "Epoch 128/300\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.3130 - val_loss: 0.9164\n",
      "Epoch 129/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.3089 - val_loss: 0.9357\n",
      "Epoch 130/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.3083 - val_loss: 0.9113\n",
      "Epoch 131/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.3077 - val_loss: 0.9333\n",
      "Epoch 132/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.3049 - val_loss: 0.9131\n",
      "Epoch 133/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.2978 - val_loss: 0.9238\n",
      "Epoch 134/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.3079 - val_loss: 0.9219\n",
      "Epoch 135/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.2962 - val_loss: 0.9185\n",
      "Epoch 136/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.2851 - val_loss: 0.9124\n",
      "Epoch 137/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.2945 - val_loss: 0.9055\n",
      "Epoch 138/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.2970 - val_loss: 0.9047\n",
      "Epoch 139/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.2888 - val_loss: 0.9103\n",
      "Epoch 140/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.2842 - val_loss: 0.9163\n",
      "Epoch 141/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.2790 - val_loss: 0.9141\n",
      "Epoch 142/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.2769 - val_loss: 0.9474\n",
      "Epoch 143/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.2845 - val_loss: 0.9085\n",
      "Epoch 144/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.2643 - val_loss: 0.9397\n",
      "Epoch 145/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.2663 - val_loss: 0.9221\n",
      "Epoch 146/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.2826 - val_loss: 0.9047\n",
      "Epoch 147/300\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.2632 - val_loss: 0.8926\n",
      "Epoch 148/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.2530 - val_loss: 0.9157\n",
      "Epoch 149/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.2564 - val_loss: 0.8889\n",
      "Epoch 150/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.2593 - val_loss: 0.8918\n",
      "Epoch 151/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.2518 - val_loss: 0.9391\n",
      "Epoch 152/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.2495 - val_loss: 0.9000\n",
      "Epoch 153/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.2513 - val_loss: 0.9025\n",
      "Epoch 154/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.2434 - val_loss: 0.8994\n",
      "Epoch 155/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.2388 - val_loss: 0.9038\n",
      "Epoch 156/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.2361 - val_loss: 0.8933\n",
      "Epoch 157/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.2270 - val_loss: 0.9118\n",
      "Epoch 158/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.2377 - val_loss: 0.9054\n",
      "Epoch 159/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.2273 - val_loss: 0.9194\n",
      "Epoch 160/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.2279 - val_loss: 0.9018\n",
      "Epoch 161/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.2224 - val_loss: 0.9190\n",
      "Epoch 162/300\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.2321 - val_loss: 0.8994\n",
      "Epoch 163/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.2213 - val_loss: 0.8927\n",
      "Epoch 164/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.2138 - val_loss: 0.8974\n",
      "Epoch 165/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.2161 - val_loss: 0.9281\n",
      "Epoch 166/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.2208 - val_loss: 0.9324\n",
      "Epoch 167/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.2297 - val_loss: 0.9340\n",
      "Epoch 168/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.2137 - val_loss: 0.8918\n",
      "Epoch 169/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.2247 - val_loss: 0.9163\n",
      "Epoch 170/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.2078 - val_loss: 0.8964\n",
      "Epoch 171/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.2153 - val_loss: 0.8968\n",
      "Epoch 172/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.2023 - val_loss: 0.8995\n",
      "Epoch 173/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.1982 - val_loss: 0.9098\n",
      "Epoch 174/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.1998 - val_loss: 0.8751\n",
      "Epoch 175/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.1945 - val_loss: 0.9093\n",
      "Epoch 176/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.1948 - val_loss: 0.9083\n",
      "Epoch 177/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.1919 - val_loss: 0.8994\n",
      "Epoch 178/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.1863 - val_loss: 0.8857\n",
      "Epoch 179/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.1896 - val_loss: 0.9041\n",
      "Epoch 180/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.1955 - val_loss: 0.9172\n",
      "Epoch 181/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.1825 - val_loss: 0.9176\n",
      "Epoch 182/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.1915 - val_loss: 0.8911\n",
      "Epoch 183/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.1804 - val_loss: 0.8869\n",
      "Epoch 184/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.1741 - val_loss: 0.8952\n",
      "Epoch 185/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.1804 - val_loss: 0.8912\n",
      "Epoch 186/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.1828 - val_loss: 0.9078\n",
      "Epoch 187/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.1777 - val_loss: 0.8848\n",
      "Epoch 188/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.1718 - val_loss: 0.9002\n",
      "Epoch 189/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.1681 - val_loss: 0.8826\n",
      "Epoch 190/300\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.1674 - val_loss: 0.8936\n",
      "Epoch 191/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.1794 - val_loss: 0.8987\n",
      "Epoch 192/300\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.1665 - val_loss: 0.8966\n",
      "Epoch 193/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.1689 - val_loss: 0.8823\n",
      "Epoch 194/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.1660 - val_loss: 0.8872\n",
      "Epoch 195/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.1708 - val_loss: 0.9104\n",
      "Epoch 196/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.1671 - val_loss: 0.8976\n",
      "Epoch 197/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.1712 - val_loss: 0.8793\n",
      "Epoch 198/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.1613 - val_loss: 0.9016\n",
      "Epoch 199/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.1563 - val_loss: 0.8748\n",
      "Epoch 200/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.1521 - val_loss: 0.8832\n",
      "Epoch 201/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.1571 - val_loss: 0.9070\n",
      "Epoch 202/300\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.1532 - val_loss: 0.9007\n",
      "Epoch 203/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.1479 - val_loss: 0.8980\n",
      "Epoch 204/300\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.1496 - val_loss: 0.9117\n",
      "Epoch 205/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.1551 - val_loss: 0.9139\n",
      "Epoch 206/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.1498 - val_loss: 0.9054\n",
      "Epoch 207/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.1435 - val_loss: 0.9002\n",
      "Epoch 208/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.1540 - val_loss: 0.9023\n",
      "Epoch 209/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.1437 - val_loss: 0.9036\n",
      "Epoch 210/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.1438 - val_loss: 0.9025\n",
      "Epoch 211/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.1423 - val_loss: 0.9062\n",
      "Epoch 212/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.1381 - val_loss: 0.9054\n",
      "Epoch 213/300\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.1370 - val_loss: 0.8874\n",
      "Epoch 214/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.1340 - val_loss: 0.8881\n",
      "Epoch 215/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.1362 - val_loss: 0.9013\n",
      "Epoch 216/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.1322 - val_loss: 0.8894\n",
      "Epoch 217/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.1382 - val_loss: 0.9053\n",
      "Epoch 218/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.1325 - val_loss: 0.8927\n",
      "Epoch 219/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.1268 - val_loss: 0.9086\n",
      "Epoch 220/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.1304 - val_loss: 0.8766\n",
      "Epoch 221/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.1254 - val_loss: 0.9111\n",
      "Epoch 222/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.1287 - val_loss: 0.8941\n",
      "Epoch 223/300\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.1274 - val_loss: 0.8880\n",
      "Epoch 224/300\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.1236 - val_loss: 0.8929\n",
      "Epoch 225/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.1172 - val_loss: 0.9192\n",
      "Epoch 226/300\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.1281 - val_loss: 0.9139\n",
      "Epoch 227/300\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.1218 - val_loss: 0.8935\n",
      "Epoch 228/300\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.1186 - val_loss: 0.8972\n",
      "Epoch 229/300\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.1224 - val_loss: 0.9270\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "if use_pca:\n",
    "    history = nn.fit(x_train, y_train_pca,batch_size=batch_size, validation_split=0.2, epochs=300, callbacks=[tf.keras.callbacks.EarlyStopping(patience=30)])\n",
    "elif use_rbf:\n",
    "    history = nn.fit(x_train, y_train_rbf,batch_size=batch_size, validation_split=0.2, epochs=300, callbacks=[tf.keras.callbacks.EarlyStopping(patience=30)])\n",
    "else:\n",
    "    history = nn.fit(x_train, y_train,batch_size=batch_size, validation_split=0.2, epochs=300, callbacks=[tf.keras.callbacks.EarlyStopping(patience=30)])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d05950e3-ad6d-4a65-8c3b-53a69a95a936",
   "metadata": {},
   "source": [
    "hist = pd.DataFrame(history.history)\n",
    "hist['epoch'] = history.epoch\n",
    "hist.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "19c54661-dfd2-427d-b701-5d85a0e74886",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss(history, y_range=[0,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cf534975-74c5-4e40-b5d1-6b77814e3e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.save('model_data/nn_'+exp_name+'.h5')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f303a6fe-f28e-4908-a68d-4fa0f7b538e4",
   "metadata": {},
   "source": [
    "nn = tf.keras.models.load_model('model_data/nn_'+exp_name+'.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a2832b-ad46-4272-b199-396274b22e8b",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "#### 2. k-Nearest Neighbor (knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a1d4a20f-e54d-4cc1-935a-258acc24965f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "knn = KNeighborsRegressor(1)\n",
    "if use_pca:\n",
    "    knn.fit(x_train, y_train_pca)\n",
    "elif use_rbf:\n",
    "    knn.fit(x_train, y_train_rbf)\n",
    "else:\n",
    "    knn.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d9968d55-ddcf-44b3-bae0-d55ffd9b262b",
   "metadata": {},
   "source": [
    "knn.save_to_file('model_data/knn_'+exp_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163a76d8-1039-49a0-aa7b-071b139ed765",
   "metadata": {},
   "source": [
    "#### 3. Gaussian Process Regressor (GPR)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d6da6e82-7ef2-43ea-938f-c66b309060b0",
   "metadata": {},
   "source": [
    "gpr = GPy_Regressor(D_in)\n",
    "if use_pca:\n",
    "    gpr.fit(x_train, y_train_pca, num_restarts = 5) # num_restarts should avoid local minima in optimization process \n",
    "elif use_rbf:\n",
    "    gpr.fit(x_train, y_train_rbf, num_restarts = 5)\n",
    "else:\n",
    "    gpr.fit(x_train, y_train, num_restarts = 5)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bb28c349-6d73-4cf9-a0a6-ae2534f542b3",
   "metadata": {},
   "source": [
    "print(gpr.gp)\n",
    "# gpr.gp.plot?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "43756deb-534c-452e-9eaa-2bc2b3e7738b",
   "metadata": {},
   "source": [
    "gpr.save_to_file('model_data/gpr_'+exp_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251d9df1-ba44-4a28-93f3-3d11094f12a4",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "#### 4 Mixture Density Network (MDN) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bc7e2067-124a-449d-b0f1-c7b3e465554b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_probability as tfp\n",
    "\n",
    "tf.keras.backend.set_floatx('float64')\n",
    "\n",
    "tfd = tfp.distributions\n",
    "tfpl = tfp.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e7f27ca8-e07b-42b4-a540-28c500e038f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_comps = 10\n",
    "n_comp_params_size = tfpl.IndependentNormal.params_size(event_shape=(D_out,))\n",
    "\n",
    "params_size = tfpl.MixtureSameFamily.params_size(num_components=n_comps, component_params_size=n_comp_params_size)\n",
    "\n",
    "mdn = Sequential([\n",
    "    Dense(256, activation='relu', input_shape=(D_in,), kernel_regularizer = tf.keras.regularizers.l2(1e-2)),\n",
    "    Dense(256, activation='relu', kernel_regularizer = tf.keras.regularizers.l2(1e-2)),\n",
    "    Dense(params_size),\n",
    "    tfpl.MixtureSameFamily(n_comps, tfpl.IndependentNormal(event_shape=(D_out,)))\n",
    "])\n",
    "\n",
    "def loss(y_true, y_pred):\n",
    "    return -y_pred.log_prob(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "845bce5f-e76f-49c4-8b4d-2c359196bd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdn.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ffe6e97c-9176-42d1-bb88-233b4a34dcc3",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "44/44 [==============================] - 1s 10ms/step - loss: 55.9347 - val_loss: 36.4927\n",
      "Epoch 2/300\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 31.9623 - val_loss: 25.8822\n",
      "Epoch 3/300\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 24.4968 - val_loss: 19.5209\n",
      "Epoch 4/300\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 20.1493 - val_loss: 17.6277\n",
      "Epoch 5/300\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 18.2945 - val_loss: 16.0776\n",
      "Epoch 6/300\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 16.8066 - val_loss: 15.7407\n",
      "Epoch 7/300\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 15.8750 - val_loss: 14.3632\n",
      "Epoch 8/300\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 14.5761 - val_loss: 13.8546\n",
      "Epoch 9/300\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 13.2172 - val_loss: 13.6156\n",
      "Epoch 10/300\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 13.1454 - val_loss: 13.3751\n",
      "Epoch 11/300\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 11.5625 - val_loss: 11.7536\n",
      "Epoch 12/300\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 10.6813 - val_loss: 10.6658\n",
      "Epoch 13/300\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 10.4142 - val_loss: 11.4309\n",
      "Epoch 14/300\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 10.3990 - val_loss: 10.5656\n",
      "Epoch 15/300\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 10.1987 - val_loss: 11.4511\n",
      "Epoch 16/300\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 9.5427 - val_loss: 10.1022\n",
      "Epoch 17/300\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 8.9165 - val_loss: 11.7715\n",
      "Epoch 18/300\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 9.0101 - val_loss: 9.6298\n",
      "Epoch 19/300\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 8.8188 - val_loss: 8.9107\n",
      "Epoch 20/300\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 8.0617 - val_loss: 9.5275\n",
      "Epoch 21/300\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 8.8503 - val_loss: 8.8898\n",
      "Epoch 22/300\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 7.7395 - val_loss: 9.7021\n",
      "Epoch 23/300\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 8.2209 - val_loss: 10.9429\n",
      "Epoch 24/300\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 7.9312 - val_loss: 8.9529\n",
      "Epoch 25/300\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 6.9747 - val_loss: 9.5136\n",
      "Epoch 26/300\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 7.3818 - val_loss: 8.1265\n",
      "Epoch 27/300\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 7.2240 - val_loss: 9.0505\n",
      "Epoch 28/300\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 6.8381 - val_loss: 8.3479\n",
      "Epoch 29/300\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 6.7647 - val_loss: 8.0905\n",
      "Epoch 30/300\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 7.1450 - val_loss: 9.0668\n",
      "Epoch 31/300\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 6.6546 - val_loss: 9.7062\n",
      "Epoch 32/300\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 7.2113 - val_loss: 8.0790\n",
      "Epoch 33/300\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 6.8137 - val_loss: 8.6696\n",
      "Epoch 34/300\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 5.6213 - val_loss: 7.7375\n",
      "Epoch 35/300\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 5.7117 - val_loss: 9.2161\n",
      "Epoch 36/300\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 6.7132 - val_loss: 8.8225\n",
      "Epoch 37/300\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 5.8461 - val_loss: 8.3992\n",
      "Epoch 38/300\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 6.3180 - val_loss: 7.8488\n",
      "Epoch 39/300\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 5.6703 - val_loss: 9.7915\n",
      "Epoch 40/300\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 6.0129 - val_loss: 8.2844\n",
      "Epoch 41/300\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 5.4414 - val_loss: 7.7140\n",
      "Epoch 42/300\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 5.2611 - val_loss: 9.8392\n",
      "Epoch 43/300\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 6.8022 - val_loss: 8.2600\n",
      "Epoch 44/300\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 5.2858 - val_loss: 7.8388\n",
      "Epoch 45/300\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 6.0962 - val_loss: 7.8901\n",
      "Epoch 46/300\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.8827 - val_loss: 8.3292\n",
      "Epoch 47/300\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 5.9440 - val_loss: 7.3043\n",
      "Epoch 48/300\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.9577 - val_loss: 8.2634\n",
      "Epoch 49/300\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.8193 - val_loss: 8.8699\n",
      "Epoch 50/300\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 5.4702 - val_loss: 7.4521\n",
      "Epoch 51/300\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.4241 - val_loss: 9.7591\n",
      "Epoch 52/300\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 5.0364 - val_loss: 8.1519\n",
      "Epoch 53/300\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 4.7751 - val_loss: 7.2495\n",
      "Epoch 54/300\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.4907 - val_loss: 8.5912\n",
      "Epoch 55/300\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.7503 - val_loss: 8.4112\n",
      "Epoch 56/300\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 4.2981 - val_loss: 7.9918\n",
      "Epoch 57/300\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.2575 - val_loss: 9.1967\n",
      "Epoch 58/300\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.3796 - val_loss: 9.6312\n",
      "Epoch 59/300\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 3.9776 - val_loss: 7.7685\n",
      "Epoch 60/300\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.0483 - val_loss: 8.0203\n",
      "Epoch 61/300\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 4.5104 - val_loss: 7.2364\n",
      "Epoch 62/300\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 4.3793 - val_loss: 7.6718\n",
      "Epoch 63/300\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 3.5894 - val_loss: 7.7239\n",
      "Epoch 64/300\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 4.3152 - val_loss: 8.2917\n",
      "Epoch 65/300\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.0852 - val_loss: 9.3245\n",
      "Epoch 66/300\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.0193 - val_loss: 9.3248\n",
      "Epoch 67/300\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 5.4561 - val_loss: 7.1702\n",
      "Epoch 68/300\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 3.5010 - val_loss: 7.7728\n",
      "Epoch 69/300\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.1494 - val_loss: 7.6479\n",
      "Epoch 70/300\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 3.7905 - val_loss: 7.6663\n",
      "Epoch 71/300\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 3.5620 - val_loss: 7.4319\n",
      "Epoch 72/300\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.5024 - val_loss: 8.6963\n",
      "Epoch 73/300\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 3.6622 - val_loss: 9.0812\n",
      "Epoch 74/300\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.1769 - val_loss: 7.5404\n",
      "Epoch 75/300\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.0783 - val_loss: 8.8559\n",
      "Epoch 76/300\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 3.5543 - val_loss: 8.7496\n",
      "Epoch 77/300\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.2778 - val_loss: 8.3007\n",
      "Epoch 78/300\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.9813 - val_loss: 7.6995\n",
      "Epoch 79/300\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 2.9792 - val_loss: 8.2244\n",
      "Epoch 80/300\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.6835 - val_loss: 8.1700\n",
      "Epoch 81/300\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 3.0016 - val_loss: 8.3099\n",
      "Epoch 82/300\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.9003 - val_loss: 7.7321\n",
      "Epoch 83/300\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.8635 - val_loss: 8.7960\n",
      "Epoch 84/300\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 2.7914 - val_loss: 10.4141\n",
      "Epoch 85/300\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.5640 - val_loss: 8.4872\n",
      "Epoch 86/300\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.6776 - val_loss: 9.4405\n",
      "Epoch 87/300\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 2.9144 - val_loss: 9.5107\n",
      "Epoch 88/300\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.8754 - val_loss: 8.3246\n",
      "Epoch 89/300\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.7577 - val_loss: 9.5077\n",
      "Epoch 90/300\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.0534 - val_loss: 8.0069\n",
      "Epoch 91/300\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.0165 - val_loss: 10.4455\n",
      "Epoch 92/300\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.7580 - val_loss: 8.3689\n",
      "Epoch 93/300\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.3093 - val_loss: 7.7348\n",
      "Epoch 94/300\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.4280 - val_loss: 8.8739\n",
      "Epoch 95/300\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 2.5084 - val_loss: 8.5431\n",
      "Epoch 96/300\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.7744 - val_loss: 7.9613\n",
      "Epoch 97/300\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 2.0784 - val_loss: 7.5735\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "if use_pca:\n",
    "    history = mdn.fit(x_train, y_train_pca,batch_size=batch_size, validation_split=0.1, epochs=300, callbacks=[tf.keras.callbacks.EarlyStopping(patience=30)], verbose=1)\n",
    "elif use_rbf:\n",
    "    history = mdn.fit(x_train, y_train_rbf,batch_size=batch_size, validation_split=0.1, epochs=300, callbacks=[tf.keras.callbacks.EarlyStopping(patience=30)])\n",
    "else:\n",
    "    history = mdn.fit(x_train, y_train,batch_size=batch_size, validation_split=0.1, epochs=300, callbacks=[tf.keras.callbacks.EarlyStopping(patience=30)])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b8de5c2e-45c9-4b4a-b3b3-879d63ee838c",
   "metadata": {
    "tags": []
   },
   "source": [
    "hist = pd.DataFrame(history.history)\n",
    "hist['epoch'] = history.epoch\n",
    "hist.tail()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d0178fbe-17d3-4442-9814-d1156be0e317",
   "metadata": {},
   "source": [
    "plot_loss(history, y_range= [0,300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "95d615ee-041f-436e-86e9-29cdc9552ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdn.save_weights('model_data/mdn_'+exp_name)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a28013e4-9aa8-4c45-819d-6743bfecbfae",
   "metadata": {},
   "source": [
    "mdn.load_weights('model_data/mdn_'+exp_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd80456-cbcb-4b6f-9664-87a00fcaa396",
   "metadata": {},
   "source": [
    "## Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "22c604ca-45a6-4914-9d1f-1069e9582c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "def predict(model, predictor, x, Dx=3, dim_red='pca', n_sample=1, take_mean = False): \n",
    "    if predictor == 'gpr':\n",
    "        y_pred, y_cov = model.predict(x, False)\n",
    "    elif predictor == 'nn':\n",
    "        y_pred = model.predict(x)\n",
    "    elif predictor == 'mdn': \n",
    "        if take_mean:\n",
    "            y_pred = np.transpose(np.array(model(x).components_distribution.mean()), axes=(1,0,2))\n",
    "        else:\n",
    "            y_pred = np.array(model(x).sample(n_sample))\n",
    "            \n",
    "    elif predictor == 'knn':\n",
    "        y_pred = model.predict(x)\n",
    "\n",
    "    #Inverse transform, if using PCA or rbf\n",
    "    if dim_red == 'pca':\n",
    "        y_traj = pca.inverse_transform(y_pred)\n",
    "    elif dim_red == 'rbf':\n",
    "        y_traj = rbf_transform.inverse_transform(y_pred)\n",
    "    elif dim_red == None:\n",
    "        y_traj = np.array(y_pred)\n",
    "    else: \n",
    "        raise NotImplementedError\n",
    "    return y_traj, y_pred "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb6ffd3-4982-4b78-812e-54db7fd784b1",
   "metadata": {},
   "source": [
    "### Quantitative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2fc93d7a-5d32-4c8e-9fe9-1b2ccae422fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = knn # options = {gpr, nn, mdn, knn}\n",
    "mode = 'knn'\n",
    "dim_red = 'pca'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e99de4-fead-4d2e-8d7a-733f1ba9ac86",
   "metadata": {},
   "source": [
    "#### Filter based on ddp cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a029fe97-48fb-4cef-85b6-6aef6e929c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mdn\n",
    "mode = 'mdn'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4544cee2-797a-4b2f-849f-5aee4c0a189f",
   "metadata": {},
   "source": [
    "#### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a71d3f02-dfdb-4aea-8ac9-8c4214a160b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dx = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "333b29d7-3552-4146-96a2-b21583e3b9d7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1.9231736860577433\n"
     ]
    }
   ],
   "source": [
    "errors = []\n",
    "goal_errors = []\n",
    "col_set = []\n",
    "true_col_set = []\n",
    "trajs = []\n",
    "K = 10\n",
    "for i in range(1):#len(x_test)): # iterate over all trajectories \n",
    "    print(i)\n",
    "    x = x_test[i]\n",
    "    y_true = y_test[i].reshape(-1,Dx)    \n",
    "    full_idx = test_idx[i]\n",
    "    obstacles = obs_set[full_idx]\n",
    "    x0, x_target = x[-24:-12], x[-12:]\n",
    "    quad_id, obj_id, init_id, target_id, border_id, obstacle_ids = init_pybullet_quadcopter(x0, x_target, obstacles)\n",
    "    if mode == 'mdn':\n",
    "        y_traj, _ = predict(model, mode, x[None,:], dim_red=dim_red, n_sample=K)\n",
    "        y_traj = y_traj.reshape(K,T,Dx)\n",
    "        y_traj, xs_init, us_init  = get_best_mdn_prediction_ddp2(y_traj, x, obstacles, general_obs=True, obj_id=obj_id, add_zeros_dim = 0)\n",
    "    else:\n",
    "        y_traj, _ = predict(model, mode, x[None,:], dim_red=dim_red)\n",
    "        y_traj = y_traj.reshape(T,Dx)\n",
    "        \n",
    "    trajs.append(y_traj)\n",
    "    residuals = np.square(np.subtract(y_traj, y_true))\n",
    "    errors.append(np.mean(residuals))\n",
    "    goal_errors.append(residuals[-1])\n",
    "    \n",
    "    #check collision\n",
    "    col_status= eval_collision_geometric_general(obstacles, obj_id, y_traj, margin = -0.01)\n",
    "    col_set.append(np.max(col_status))\n",
    "\n",
    "    col_status= eval_collision_geometric_general(obstacles, obj_id, y_true)\n",
    "    true_col_set.append(np.max(col_status))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ca43f0a4-4c68-4101-956d-227bdb4982ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0172\n",
      "0.0020\n",
      "0.2447\n"
     ]
    }
   ],
   "source": [
    "col_percent = (1-np.sum(col_set)/len(col_set))\n",
    "print('MSE total: {0:.4f}'.format(total_mse))\n",
    "print('MSE goal: {0:.4f}'.format(goal_mse))\n",
    "print('Collision free (%): {0:.4f}'.format(col_percent*100))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
